### n-dimension histogram

* bin 划分和考试要求


### Histogram matching


### homework 1 讲解


### Otsu threshold


### Entropy Method threshold

1. 阈值化准则：
$$H = H_1 + H_2$$

其中：
- $H_1 = -\sum_{i=0}^{k} \frac{p_i}{P_1} \log_2 \frac{p_i}{P_1}$ （背景类熵）
- $H_2 = -\sum_{i=k+1}^{L-1} \frac{p_i}{P_2} \log_2 \frac{p_i}{P_2}$ （前景类熵）
- $P_1 = \sum_{i=0}^{k} p_i$，$P_2 = \sum_{i=k+1}^{L-1} p_i = 1 - P_1$

2. 展开 $H_2$ 项

$$H_2 = -\sum_{i=k+1}^{L-1} \frac{p_i}{P_2} \log_2 \frac{p_i}{P_2}$$
$$= -\frac{1}{P_2} \sum_{i=k+1}^{L-1} p_i [\log_2 p_i - \log_2 P_2]$$
$$= -\frac{1}{P_2} \sum_{i=k+1}^{L-1} p_i \log_2 p_i + \frac{1}{P_2} \log_2 P_2 \sum_{i=k+1}^{L-1} p_i$$
$$= -\frac{1}{P_2} \sum_{i=k+1}^{L-1} p_i \log_2 p_i + \log_2 P_2$$

3. 利用全图像熵 $H(I)$

全图像熵定义：
$$H(I) = -\sum_{i=0}^{L-1} p_i \log_2 p_i$$

关键恒等式：
$$\sum_{i=k+1}^{L-1} p_i \log_2 p_i = -H(I) - \sum_{i=0}^{k} p_i \log_2 p_i$$

4. 重新整理 $H_2$

将步骤3的结果代入步骤2：
$$H_2 = -\frac{1}{P_2} [-H(I) - \sum_{i=0}^{k} p_i \log_2 p_i] + \log_2 P_2$$
$$= \frac{1}{P_2} [H(I) + \sum_{i=0}^{k} p_i \log_2 p_i] + \log_2 P_2$$

5. 展开 $H_1$

$$H_1 = -\sum_{i=0}^{k} \frac{p_i}{P_1} \log_2 \frac{p_i}{P_1}$$
$$= -\frac{1}{P_1} \sum_{i=0}^{k} p_i [\log_2 p_i - \log_2 P_1]$$
$$= -\frac{1}{P_1} \sum_{i=0}^{k} p_i \log_2 p_i + \log_2 P_1$$

6. 组合得到总熵

$$H = H_1 + H_2$$
$$= -\frac{1}{P_1} \sum_{i=0}^{k} p_i \log_2 p_i + \log_2 P_1 + \frac{1}{P_2} [H(I) + \sum_{i=0}^{k} p_i \log_2 p_i] + \log_2 P_2$$

7. 最终整理

令 $S_k = \sum_{i=0}^{k} p_i \log_2 p_i$，则：

$$H = -\frac{S_k}{P_1} + \log_2 P_1 + \frac{H(I) + S_k}{P_2} + \log_2 P_2$$

$$= S_k \left(\frac{1}{P_2} - \frac{1}{P_1}\right) + \frac{H(I)}{P_2} + \log_2 (P_1 P_2)$$

$$= S_k \left(\frac{P_1 - P_2}{P_1 P_2}\right) + \frac{H(I)}{P_2} + \log_2 (P_1 P_2)$$

由于 $P_2 = 1 - P_1$，所以 $P_1 - P_2 = 2P_1 - 1$：

$$H = S_k \left(\frac{2P_1 - 1}{P_1(1-P_1)}\right) + \frac{H(I)}{1-P_1} + \log_2 [P_1(1-P_1)]$$


### 采样与量化


### Nearest neighbor interpolation(NN)


### Linear interpolation

* 权重是对角方向矩形的面积
* n-dimension 维度线性插值就拆分为 n 次 1-dimension线性插值


推导方式一：双线性插值的通用多项式
$$v(x,y) = ax + by + cxy + d$$
这个插值曲面必须精确地穿过四个已知的角点，因此可以将这四个点的坐标和值代入上式

1.  **代入点 $(0,0)$**：$f(0,0) = a(0) + b(0) + c(0)(0) + d$，于是 $d = f(0,0)$

2.  **代入点 $(1,0)$**：f(1,0) = a(1) + b(0) + c(1)(0) + d = a + d$，将 (1) 的结果代入，得到 $a = f(1,0) - d=f(1,0)-f(0,0)$

3.  **代入点 $(0,1)$**：$f(0,1) = a(0) + b(1) + c(0)(1) + d = b + d$，将 (1) 的结果代入，得到 $b = f(0,1) - d=f(0,1) - f(0,0)$

4.  **代入点 $(1,1)$**：$f(1,1) = a(1) + b(1) + c(1)(1) + d = a + b + c + d$，将 (1), (2), (3) 的结果全部代入，求解 $c$：$c = f(1,1) - f(1,0) - f(0,1) + f(0,0)$


推导方式二：分解为多个一元线性插值

1. 在 x 方向进行两次一维线性插值

* 正方形的底边（$y=0$）上，对点 $(0,0)$ 和 $(1,0)$ 之间进行线性插值
$$f(R_1) = f(0,0)(1-x) + f(1,0)x$$

* 正方形的顶边（$y=1$）上，对点 $(0,1)$ 和 $(1,1)$ 之间进行线性插值
$$f(R_2) = f(0,1)(1-x) + f(1,1)x$$

2. 在 y 方向进行一次一维线性插值

* 对点 $R_1 = (x,0)$ 和 $R_2 = (x,1)$ 在 y 方向进行插值：
$$v(x,y) = f(R_1)(1-y) + f(R_2)y$$

3. 代入并展开
$$v(x,y) = [f(0,0)(1-x) + f(1,0)x](1-y) + [f(0,1)(1-x) + f(1,1)x]y$$
	发现
	$v(x,y) = f(0,0) \cdot 1$
	$+ [-f(0,0) + f(1,0)]x$
	$+ [-f(0,0) + f(0,1)]y$
	$+ [f(0,0) - f(1,0) - f(0,1) + f(1,1)]xy$


### Cubic polynomial interpolation

双三次插值 (Bicubic Interpolation)，它是一种通过在待求像素点周围的 $4 \times 4$ 网格内，利用16个最近邻像素来估计新像素值的方法

* 一维三次插值：一个常用的三次卷积核
$$W(x) = \begin{cases} (a+2)|x|^3 - (a+3)|x|^2 + 1 & \text{for } |x| \le 1 \\ a|x|^3 - 5a|x|^2 + 8a|x| - 4a & \text{for } 1 < |x| < 2 \\ 0 & \text{otherwise} \end{cases}$$
 $a$ 是一个可调参数，通常取值为-0.5或-0.75，当 $a=-0.5$ 时，该核函数能保证插值函数的一阶导数连续，从而获得平滑的插值结果。


* 二维双三次插值过程

	1.  行插值：对于 $4 \times 4$ 邻域中的每一行（共4行），使用该行上的4个像素点和一维三次卷积核，计算出目标点 $x$ 坐标位置上的4个中间值。
	2.  列插值：使用上一步得到的4个位于同一列的中间值，再次使用一维三次卷积核，计算出目标点 $(x,y)$ 的最终像素值。

* 数学模型 $$v(x,y) = \sum_{i=0}^{3} \sum_{j=0}^{3} a_{ij} x^i y^j$$


### 超分

图像超分辨率 (Super-Resolution, SR) 旨在从低分辨率 (LR) 图像中恢复出高分辨率 (HR) 图像。它不仅是放大图像，更关键的是要恢复出物理上真实存在但因采样不足而丢失的高频细节。

* 超分辨率的核心是解决一个逆问题。通常，LR图像的降质模型可以表示为：
	$$Y = (X \otimes K) \downarrow_s + N$$
    其中，$Y$ 是观测到的LR图像，$X$ 是我们想要恢复的HR图像，$K$ 是模糊核（如高斯模糊），$\otimes$ 代表卷积操作，$\downarrow_s$ 是下采样操作（尺度因子为s），$N$ 是加性噪声。超分算法的目标就是根据 $Y$ 来求解 $X$。

* **主流算法分类**

	1. 基于插值的方法 (Interpolation)

    2. 基于重建的方法 (Reconstruction)

	* 这类方法通过引入先验知识来约束解空间，从而获得更好的重建结果。
	* 原理：超分辨率看作一个最大后验概率 (MAP) 估计问题，找到最可能的HR图像 $X$：
    $$\hat{X} = \arg\max_X P(X|Y) \propto \arg\max_X P(Y|X)P(X)$$
	    $P(Y|X)$ 是似然项，描述了在给定HR图像$X$的情况下，观测到LR图像$Y$的概率，它由降质模型决定；$P(X)$ 是先验项，代表了我们对自然图像特征的先验知识，例如图像的边缘是稀疏的（稀疏编码模型）或平滑的。
 

    3. 基于深度学习的方法

	* SRCNN (Super-Resolution Convolutional Neural Network)：作为开创性工作，它证明了CNN可以用于SR。其结构包含三个卷积层，分别对应：
		1.  块提取与表示：从插值放大的 LR 图像中提取特征。
		2.  非线性映射：将 LR 特征非线性地映射到 HR 特征。
		3.  重建：将HR特征组合成最终的 HR 图像。

	* 基于残差学习的更快、更深的网络 (如VDSR, EDSR)：为了构建更深的网络以提升性能，后续模型引入了残差学习。网络不再直接学习HR图像，而是学习 HR 图像与插值后的 LR 图像之间的残差（即高频细节）。由于残差图像大部分区域接近于零，学习目标更简单，使得网络可以构建得非常深，效果也更好。

	* 基于生成对抗网络的方法 (GAN-based, 如SRGAN)：为了解决传统方法（基于MSE损失函数）结果过于平滑、缺乏真实感的问题，SRGAN引入了生成对抗网络。
		* 它包含一个生成器 (Generator)，负责生成 HR 图像；以及一个判别器 (Discriminator)，负责判断输入是真实的HR图像还是生成器生成的图像。
		* 两者相互博弈，驱使生成器产生看起来真实、纹理细节丰富的高分辨率图像，其损失函数通常包含像素级的内容损失和使结果更逼真的对抗损失与感知损失。


### 卷积和相关